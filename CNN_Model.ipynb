{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_Model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpZrzjwMf9N1"
      },
      "source": [
        "import numpy as np\n",
        "def extractfeatures(x, sr, features):\n",
        "    result = np.array([])\n",
        "\n",
        "    for feature in features:\n",
        "      if feature=='MFCC':\n",
        "        #MFCC\n",
        "        mfcc = np.mean(librosa.feature.mfcc(y=x, sr=sr).T, axis=0)\n",
        "        result = np.hstack((result, mfcc)) \n",
        "      if feature=='Spectral Centroid':\n",
        "        #Spectral Centroid\n",
        "        specc = np.mean(librosa.feature.spectral_centroid(y=x, sr=sr)[0])\n",
        "        result = np.hstack((result, specc))\n",
        "      if feature=='Spectral Bandwidth':\n",
        "        #Spectral Centroid\n",
        "        specb = np.mean(librosa.feature.spectral_bandwidth(y=x, sr=sr)[0])\n",
        "        result = np.hstack((result, specb)) \n",
        "      if feature=='Spectral Contrast':\n",
        "        #Spectral Centroid\n",
        "        speco = np.mean(librosa.feature.spectral_contrast(y=x, sr=sr)[0])\n",
        "        result = np.hstack((result, speco))\n",
        "      if feature=='Spectral Rolloff':\n",
        "        #Spectral Rolloff\n",
        "        specr = np.mean(librosa.feature.spectral_rolloff(y=x, sr=sr))\n",
        "        result = np.hstack((result, specr))\n",
        "      if feature=='Fourier Tempogram':\n",
        "        #Fourier Tempogram\n",
        "        fouriert = np.mean(librosa.feature.fourier_tempogram(y=x, sr=sr))\n",
        "        result = np.hstack((result, fouriert))\n",
        "      if feature=='Chroma':\n",
        "        #Chroma\n",
        "        chroma = np.abs(librosa.stft(x))\n",
        "        chroma_stft = np.mean(librosa.feature.chroma_stft(S=chroma, sr=sr).T, axis=0)\n",
        "        result = np.hstack((result, chroma_stft))\n",
        "  \n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "8fr0jxKT21Ly",
        "outputId": "024fa076-27ea-4cb8-ce25-94db4f5e7fd5"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import librosa\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "  \n",
        "# Then move kaggle.json into the folder where the API expects to find it.\n",
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-20efd316-c58d-44cb-91be-7d2eadb43434\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-20efd316-c58d-44cb-91be-7d2eadb43434\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "User uploaded file \"kaggle.json\" with length 65 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBG6xr_720D8",
        "outputId": "e73f3717-5b51-42bf-81ad-80fa668814c9"
      },
      "source": [
        "!kaggle datasets download -d uwrfkaggler/ravdess-emotional-speech-audio"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading ravdess-emotional-speech-audio.zip to /content\n",
            " 97% 417M/429M [00:03<00:00, 122MB/s]\n",
            "100% 429M/429M [00:03<00:00, 118MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSs7T8ClauBH"
      },
      "source": [
        "!unzip ravdess-emotional-speech-audio.zip -d /content/Actor_folders"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQo1tDKaaH86"
      },
      "source": [
        "import os\n",
        "from glob import iglob\n",
        "\n",
        "rootdir_glob = '/content/Actor_folders/**/*' # Note the added asterisks\n",
        "# This will return absolute paths\n",
        "orig_file_list = [f for f in iglob(rootdir_glob, recursive=True) if os.path.isfile(f)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibsQtbTe-rS1"
      },
      "source": [
        "from random import sample\n",
        "import copy\n",
        "import sklearn\n",
        "\n",
        "X=[]\n",
        "y=[]\n",
        "\n",
        "for i in range (len(orig_file_list)):\n",
        "\n",
        "  x , sr = librosa.load(orig_file_list[i])\n",
        "  result=extractfeatures(x, sr,['MFCC','Spectral Centroid','Spectral Rolloff','Spectral Contrast','Spectral Bandwidth'])\n",
        "  X.append(result)\n",
        "\n",
        "  audio_path=orig_file_list[i].split('/')[4:][0]\n",
        "  parts=audio_path.split('.')[0].split('-')\n",
        "  y.append(int(parts[2]))\n",
        "\n",
        "y=np.array(y)\n",
        "X=np.array(X)\n",
        "\n",
        "y=y.reshape(-1,1)\n",
        "X=X.reshape(X.shape[0],X.shape[1],1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWNXNDmMn0FP"
      },
      "source": [
        "def build_cnn_model(input_shape=(X.shape[1],1), num_class=9, dropout_rate=0.1):\n",
        "\n",
        "  model = tf.keras.models.Sequential([\n",
        "            tf.keras.layers.Conv1D(32*6, 3, activation='relu', input_shape=input_shape),\n",
        "            tf.keras.layers.Dropout(dropout_rate),\n",
        "            tf.keras.layers.MaxPooling1D(2),\n",
        "            tf.keras.layers.Conv1D(64, 3, activation='relu'),\n",
        "            tf.keras.layers.Dropout(dropout_rate),\n",
        "            tf.keras.layers.MaxPooling1D(2),\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dense(64, activation='relu'),\n",
        "            tf.keras.layers.Dense(num_class, activation='softmax')\n",
        "        ])\n",
        "  # -------------------------------\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQoNIGVDtFiu"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_history(history):\n",
        "  # function to plot accuracy vs epoch\n",
        "\n",
        "  plt.plot(history.history['accuracy'], label='accuracy')\n",
        "  plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.legend(loc='lower right')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9_rSD_TYmAtc",
        "outputId": "b70fe60b-f8d0-4bff-f53b-7f77cce2f292"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=42)\n",
        "\n",
        "model=build_cnn_model()\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(), loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=500, batch_size=128,validation_data=(X_test, y_test))\n",
        "\n",
        "plot_history(history)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 65.2520 - accuracy: 0.1204 - val_loss: 11.9016 - val_accuracy: 0.1250\n",
            "Epoch 2/500\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 22.1919 - accuracy: 0.1412 - val_loss: 4.2811 - val_accuracy: 0.1736\n",
            "Epoch 3/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 11.0501 - accuracy: 0.1474 - val_loss: 3.7897 - val_accuracy: 0.1597\n",
            "Epoch 4/500\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 5.9343 - accuracy: 0.1566 - val_loss: 2.7178 - val_accuracy: 0.1181\n",
            "Epoch 5/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 4.0688 - accuracy: 0.1705 - val_loss: 2.1876 - val_accuracy: 0.1667\n",
            "Epoch 6/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 2.9103 - accuracy: 0.1798 - val_loss: 2.1128 - val_accuracy: 0.2361\n",
            "Epoch 7/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 2.3003 - accuracy: 0.1698 - val_loss: 2.0093 - val_accuracy: 0.1875\n",
            "Epoch 8/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 2.1693 - accuracy: 0.1883 - val_loss: 2.0070 - val_accuracy: 0.1944\n",
            "Epoch 9/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 2.0623 - accuracy: 0.2106 - val_loss: 2.0121 - val_accuracy: 0.2083\n",
            "Epoch 10/500\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 2.0684 - accuracy: 0.1960 - val_loss: 2.0037 - val_accuracy: 0.2014\n",
            "Epoch 11/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 2.0046 - accuracy: 0.2284 - val_loss: 2.0069 - val_accuracy: 0.1875\n",
            "Epoch 12/500\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 1.9720 - accuracy: 0.2346 - val_loss: 1.9353 - val_accuracy: 0.2361\n",
            "Epoch 13/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.9414 - accuracy: 0.2593 - val_loss: 1.9223 - val_accuracy: 0.2639\n",
            "Epoch 14/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.8960 - accuracy: 0.2801 - val_loss: 1.8804 - val_accuracy: 0.2986\n",
            "Epoch 15/500\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 1.8862 - accuracy: 0.2855 - val_loss: 1.8647 - val_accuracy: 0.2986\n",
            "Epoch 16/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.8315 - accuracy: 0.3040 - val_loss: 1.8672 - val_accuracy: 0.2778\n",
            "Epoch 17/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.8129 - accuracy: 0.3194 - val_loss: 1.8533 - val_accuracy: 0.3194\n",
            "Epoch 18/500\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 1.8174 - accuracy: 0.3110 - val_loss: 1.8227 - val_accuracy: 0.3333\n",
            "Epoch 19/500\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 1.8045 - accuracy: 0.3164 - val_loss: 1.7852 - val_accuracy: 0.3889\n",
            "Epoch 20/500\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 1.7926 - accuracy: 0.3187 - val_loss: 1.7790 - val_accuracy: 0.3611\n",
            "Epoch 21/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.7537 - accuracy: 0.3465 - val_loss: 1.7716 - val_accuracy: 0.3819\n",
            "Epoch 22/500\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 1.7320 - accuracy: 0.3472 - val_loss: 1.7612 - val_accuracy: 0.3542\n",
            "Epoch 23/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.7400 - accuracy: 0.3472 - val_loss: 1.7442 - val_accuracy: 0.3889\n",
            "Epoch 24/500\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 1.6809 - accuracy: 0.3812 - val_loss: 1.7314 - val_accuracy: 0.4097\n",
            "Epoch 25/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.6886 - accuracy: 0.3711 - val_loss: 1.7290 - val_accuracy: 0.3472\n",
            "Epoch 26/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.6868 - accuracy: 0.3588 - val_loss: 1.7210 - val_accuracy: 0.3681\n",
            "Epoch 27/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.6599 - accuracy: 0.3796 - val_loss: 1.6901 - val_accuracy: 0.3750\n",
            "Epoch 28/500\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 1.6431 - accuracy: 0.3873 - val_loss: 1.6809 - val_accuracy: 0.3819\n",
            "Epoch 29/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 1.6482 - accuracy: 0.3727 - val_loss: 1.7216 - val_accuracy: 0.3333\n",
            "Epoch 30/500\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 1.6434 - accuracy: 0.3843 - val_loss: 1.6662 - val_accuracy: 0.4306\n",
            "Epoch 31/500\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 1.6359 - accuracy: 0.3951 - val_loss: 1.6882 - val_accuracy: 0.3889\n",
            "Epoch 32/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.6199 - accuracy: 0.4097 - val_loss: 1.6697 - val_accuracy: 0.3819\n",
            "Epoch 33/500\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 1.6099 - accuracy: 0.4059 - val_loss: 1.6562 - val_accuracy: 0.3958\n",
            "Epoch 34/500\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 1.6097 - accuracy: 0.4090 - val_loss: 1.6679 - val_accuracy: 0.3611\n",
            "Epoch 35/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 1.5916 - accuracy: 0.4097 - val_loss: 1.6492 - val_accuracy: 0.3819\n",
            "Epoch 36/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.5636 - accuracy: 0.4090 - val_loss: 1.6338 - val_accuracy: 0.4028\n",
            "Epoch 37/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.5666 - accuracy: 0.4329 - val_loss: 1.7069 - val_accuracy: 0.3264\n",
            "Epoch 38/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.5648 - accuracy: 0.4120 - val_loss: 1.6321 - val_accuracy: 0.4028\n",
            "Epoch 39/500\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 1.5565 - accuracy: 0.4174 - val_loss: 1.6422 - val_accuracy: 0.3819\n",
            "Epoch 40/500\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 1.5528 - accuracy: 0.4344 - val_loss: 1.6319 - val_accuracy: 0.3958\n",
            "Epoch 41/500\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 1.5485 - accuracy: 0.4221 - val_loss: 1.6495 - val_accuracy: 0.3889\n",
            "Epoch 42/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.5538 - accuracy: 0.4159 - val_loss: 1.6134 - val_accuracy: 0.4097\n",
            "Epoch 43/500\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 1.5094 - accuracy: 0.4414 - val_loss: 1.6166 - val_accuracy: 0.4236\n",
            "Epoch 44/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.5286 - accuracy: 0.4290 - val_loss: 1.6172 - val_accuracy: 0.3611\n",
            "Epoch 45/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.5009 - accuracy: 0.4591 - val_loss: 1.5994 - val_accuracy: 0.4028\n",
            "Epoch 46/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.4944 - accuracy: 0.4560 - val_loss: 1.5630 - val_accuracy: 0.4097\n",
            "Epoch 47/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 1.4722 - accuracy: 0.4614 - val_loss: 1.5354 - val_accuracy: 0.4514\n",
            "Epoch 48/500\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 1.4681 - accuracy: 0.4699 - val_loss: 1.5892 - val_accuracy: 0.4028\n",
            "Epoch 49/500\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 1.4611 - accuracy: 0.4761 - val_loss: 1.5522 - val_accuracy: 0.3958\n",
            "Epoch 50/500\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 1.4416 - accuracy: 0.4676 - val_loss: 1.5322 - val_accuracy: 0.4167\n",
            "Epoch 51/500\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 1.4400 - accuracy: 0.4722 - val_loss: 1.5697 - val_accuracy: 0.4028\n",
            "Epoch 52/500\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 1.4531 - accuracy: 0.4823 - val_loss: 1.5487 - val_accuracy: 0.4444\n",
            "Epoch 53/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.4222 - accuracy: 0.4784 - val_loss: 1.5339 - val_accuracy: 0.4375\n",
            "Epoch 54/500\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 1.4517 - accuracy: 0.4730 - val_loss: 1.5233 - val_accuracy: 0.4653\n",
            "Epoch 55/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.3988 - accuracy: 0.4961 - val_loss: 1.5470 - val_accuracy: 0.3889\n",
            "Epoch 56/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 1.3983 - accuracy: 0.4776 - val_loss: 1.5313 - val_accuracy: 0.3958\n",
            "Epoch 57/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.3985 - accuracy: 0.4784 - val_loss: 1.5137 - val_accuracy: 0.4583\n",
            "Epoch 58/500\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 1.3636 - accuracy: 0.5162 - val_loss: 1.5112 - val_accuracy: 0.4306\n",
            "Epoch 59/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 1.3530 - accuracy: 0.5193 - val_loss: 1.5014 - val_accuracy: 0.4375\n",
            "Epoch 60/500\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 1.3413 - accuracy: 0.5077 - val_loss: 1.5351 - val_accuracy: 0.4167\n",
            "Epoch 61/500\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 1.3260 - accuracy: 0.5285 - val_loss: 1.4782 - val_accuracy: 0.5000\n",
            "Epoch 62/500\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 1.3385 - accuracy: 0.5316 - val_loss: 1.4931 - val_accuracy: 0.4444\n",
            "Epoch 63/500\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 1.3047 - accuracy: 0.5401 - val_loss: 1.4820 - val_accuracy: 0.4792\n",
            "Epoch 64/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 1.2925 - accuracy: 0.5262 - val_loss: 1.5395 - val_accuracy: 0.4375\n",
            "Epoch 65/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.3216 - accuracy: 0.5355 - val_loss: 1.4949 - val_accuracy: 0.4514\n",
            "Epoch 66/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.3015 - accuracy: 0.5231 - val_loss: 1.4987 - val_accuracy: 0.4375\n",
            "Epoch 67/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.2874 - accuracy: 0.5502 - val_loss: 1.4432 - val_accuracy: 0.5000\n",
            "Epoch 68/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 1.2551 - accuracy: 0.5355 - val_loss: 1.4935 - val_accuracy: 0.4653\n",
            "Epoch 69/500\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 1.2529 - accuracy: 0.5463 - val_loss: 1.4684 - val_accuracy: 0.4861\n",
            "Epoch 70/500\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 1.2850 - accuracy: 0.5216 - val_loss: 1.4735 - val_accuracy: 0.4653\n",
            "Epoch 71/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 1.2649 - accuracy: 0.5386 - val_loss: 1.4542 - val_accuracy: 0.4722\n",
            "Epoch 72/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.2583 - accuracy: 0.5509 - val_loss: 1.5239 - val_accuracy: 0.4722\n",
            "Epoch 73/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.2123 - accuracy: 0.5625 - val_loss: 1.4448 - val_accuracy: 0.5069\n",
            "Epoch 74/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.2246 - accuracy: 0.5556 - val_loss: 1.4509 - val_accuracy: 0.4792\n",
            "Epoch 75/500\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 1.1926 - accuracy: 0.5648 - val_loss: 1.4476 - val_accuracy: 0.4931\n",
            "Epoch 76/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 1.2128 - accuracy: 0.5633 - val_loss: 1.4975 - val_accuracy: 0.4792\n",
            "Epoch 77/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 1.2021 - accuracy: 0.5710 - val_loss: 1.4333 - val_accuracy: 0.5278\n",
            "Epoch 78/500\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 1.1733 - accuracy: 0.5702 - val_loss: 1.4357 - val_accuracy: 0.4653\n",
            "Epoch 79/500\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 1.1977 - accuracy: 0.5718 - val_loss: 1.4887 - val_accuracy: 0.5069\n",
            "Epoch 80/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.1881 - accuracy: 0.5664 - val_loss: 1.4148 - val_accuracy: 0.5208\n",
            "Epoch 81/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.1414 - accuracy: 0.5903 - val_loss: 1.4643 - val_accuracy: 0.4792\n",
            "Epoch 82/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.1576 - accuracy: 0.5710 - val_loss: 1.4181 - val_accuracy: 0.5139\n",
            "Epoch 83/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.1296 - accuracy: 0.5949 - val_loss: 1.4157 - val_accuracy: 0.5139\n",
            "Epoch 84/500\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 1.1375 - accuracy: 0.6026 - val_loss: 1.4591 - val_accuracy: 0.4792\n",
            "Epoch 85/500\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 1.1561 - accuracy: 0.5710 - val_loss: 1.4027 - val_accuracy: 0.5208\n",
            "Epoch 86/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.1234 - accuracy: 0.5995 - val_loss: 1.4244 - val_accuracy: 0.4861\n",
            "Epoch 87/500\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 1.1204 - accuracy: 0.5903 - val_loss: 1.4118 - val_accuracy: 0.4722\n",
            "Epoch 88/500\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 1.0920 - accuracy: 0.6042 - val_loss: 1.4028 - val_accuracy: 0.4931\n",
            "Epoch 89/500\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 1.0901 - accuracy: 0.6088 - val_loss: 1.4281 - val_accuracy: 0.5278\n",
            "Epoch 90/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 1.0919 - accuracy: 0.6049 - val_loss: 1.4219 - val_accuracy: 0.4861\n",
            "Epoch 91/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.0620 - accuracy: 0.6111 - val_loss: 1.4149 - val_accuracy: 0.4861\n",
            "Epoch 92/500\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 1.0719 - accuracy: 0.6196 - val_loss: 1.4840 - val_accuracy: 0.5208\n",
            "Epoch 93/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.0517 - accuracy: 0.6173 - val_loss: 1.4247 - val_accuracy: 0.4792\n",
            "Epoch 94/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.0316 - accuracy: 0.6358 - val_loss: 1.4169 - val_accuracy: 0.4931\n",
            "Epoch 95/500\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 1.0467 - accuracy: 0.6134 - val_loss: 1.4225 - val_accuracy: 0.5139\n",
            "Epoch 96/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.0826 - accuracy: 0.6042 - val_loss: 1.3791 - val_accuracy: 0.5278\n",
            "Epoch 97/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.0274 - accuracy: 0.6389 - val_loss: 1.3642 - val_accuracy: 0.5139\n",
            "Epoch 98/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.0267 - accuracy: 0.6366 - val_loss: 1.4456 - val_accuracy: 0.4583\n",
            "Epoch 99/500\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 1.0559 - accuracy: 0.6134 - val_loss: 1.4140 - val_accuracy: 0.5000\n",
            "Epoch 100/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.0261 - accuracy: 0.6157 - val_loss: 1.3655 - val_accuracy: 0.5278\n",
            "Epoch 101/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.0360 - accuracy: 0.6327 - val_loss: 1.3994 - val_accuracy: 0.4653\n",
            "Epoch 102/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.9694 - accuracy: 0.6505 - val_loss: 1.3963 - val_accuracy: 0.5069\n",
            "Epoch 103/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.9555 - accuracy: 0.6613 - val_loss: 1.3592 - val_accuracy: 0.5069\n",
            "Epoch 104/500\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.9570 - accuracy: 0.6543 - val_loss: 1.3617 - val_accuracy: 0.5208\n",
            "Epoch 105/500\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.9704 - accuracy: 0.6427 - val_loss: 1.3722 - val_accuracy: 0.5139\n",
            "Epoch 106/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.9622 - accuracy: 0.6559 - val_loss: 1.4514 - val_accuracy: 0.4444\n",
            "Epoch 107/500\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.9697 - accuracy: 0.6505 - val_loss: 1.3720 - val_accuracy: 0.5208\n",
            "Epoch 108/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.9683 - accuracy: 0.6597 - val_loss: 1.3938 - val_accuracy: 0.5069\n",
            "Epoch 109/500\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.9368 - accuracy: 0.6605 - val_loss: 1.3524 - val_accuracy: 0.5417\n",
            "Epoch 110/500\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.9129 - accuracy: 0.6690 - val_loss: 1.3860 - val_accuracy: 0.5069\n",
            "Epoch 111/500\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.9102 - accuracy: 0.6674 - val_loss: 1.4033 - val_accuracy: 0.5000\n",
            "Epoch 112/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.9063 - accuracy: 0.6790 - val_loss: 1.4094 - val_accuracy: 0.5486\n",
            "Epoch 113/500\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.9026 - accuracy: 0.6674 - val_loss: 1.3853 - val_accuracy: 0.5000\n",
            "Epoch 114/500\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.9152 - accuracy: 0.6659 - val_loss: 1.3825 - val_accuracy: 0.5208\n",
            "Epoch 115/500\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.9240 - accuracy: 0.6590 - val_loss: 1.4094 - val_accuracy: 0.5000\n",
            "Epoch 116/500\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.9130 - accuracy: 0.6728 - val_loss: 1.3792 - val_accuracy: 0.5069\n",
            "Epoch 117/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.8999 - accuracy: 0.6775 - val_loss: 1.3918 - val_accuracy: 0.4931\n",
            "Epoch 118/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.8867 - accuracy: 0.6674 - val_loss: 1.3877 - val_accuracy: 0.5208\n",
            "Epoch 119/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.9125 - accuracy: 0.6728 - val_loss: 1.3615 - val_accuracy: 0.5000\n",
            "Epoch 120/500\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.8936 - accuracy: 0.6821 - val_loss: 1.3947 - val_accuracy: 0.4931\n",
            "Epoch 121/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.8718 - accuracy: 0.6813 - val_loss: 1.3413 - val_accuracy: 0.5069\n",
            "Epoch 122/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.8787 - accuracy: 0.6813 - val_loss: 1.4198 - val_accuracy: 0.4931\n",
            "Epoch 123/500\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.8582 - accuracy: 0.6937 - val_loss: 1.3379 - val_accuracy: 0.5069\n",
            "Epoch 124/500\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.8857 - accuracy: 0.6806 - val_loss: 1.3429 - val_accuracy: 0.5139\n",
            "Epoch 125/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.8731 - accuracy: 0.6860 - val_loss: 1.4088 - val_accuracy: 0.4931\n",
            "Epoch 126/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.8882 - accuracy: 0.6705 - val_loss: 1.4409 - val_accuracy: 0.5486\n",
            "Epoch 127/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.8625 - accuracy: 0.6898 - val_loss: 1.4307 - val_accuracy: 0.4653\n",
            "Epoch 128/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.8421 - accuracy: 0.6968 - val_loss: 1.4073 - val_accuracy: 0.5139\n",
            "Epoch 129/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.8421 - accuracy: 0.6944 - val_loss: 1.4212 - val_accuracy: 0.5139\n",
            "Epoch 130/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.8339 - accuracy: 0.6890 - val_loss: 1.3351 - val_accuracy: 0.5347\n",
            "Epoch 131/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.8104 - accuracy: 0.7160 - val_loss: 1.4040 - val_accuracy: 0.5069\n",
            "Epoch 132/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.7945 - accuracy: 0.7037 - val_loss: 1.3972 - val_accuracy: 0.5069\n",
            "Epoch 133/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.7870 - accuracy: 0.7230 - val_loss: 1.3638 - val_accuracy: 0.5208\n",
            "Epoch 134/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.8152 - accuracy: 0.7052 - val_loss: 1.3528 - val_accuracy: 0.5208\n",
            "Epoch 135/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.7803 - accuracy: 0.7114 - val_loss: 1.3548 - val_accuracy: 0.5278\n",
            "Epoch 136/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.7733 - accuracy: 0.7253 - val_loss: 1.3284 - val_accuracy: 0.5278\n",
            "Epoch 137/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.7727 - accuracy: 0.7091 - val_loss: 1.3896 - val_accuracy: 0.5347\n",
            "Epoch 138/500\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.8015 - accuracy: 0.6991 - val_loss: 1.3892 - val_accuracy: 0.5139\n",
            "Epoch 139/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.7662 - accuracy: 0.7361 - val_loss: 1.3449 - val_accuracy: 0.5208\n",
            "Epoch 140/500\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.7507 - accuracy: 0.7292 - val_loss: 1.3673 - val_accuracy: 0.5139\n",
            "Epoch 141/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.7554 - accuracy: 0.7284 - val_loss: 1.4307 - val_accuracy: 0.5139\n",
            "Epoch 142/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.7489 - accuracy: 0.7369 - val_loss: 1.3246 - val_accuracy: 0.5208\n",
            "Epoch 143/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.7693 - accuracy: 0.7253 - val_loss: 1.3802 - val_accuracy: 0.5556\n",
            "Epoch 144/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.7510 - accuracy: 0.7299 - val_loss: 1.3102 - val_accuracy: 0.5486\n",
            "Epoch 145/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.7142 - accuracy: 0.7438 - val_loss: 1.3276 - val_accuracy: 0.5278\n",
            "Epoch 146/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.7170 - accuracy: 0.7469 - val_loss: 1.2846 - val_accuracy: 0.5139\n",
            "Epoch 147/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.7272 - accuracy: 0.7323 - val_loss: 1.3837 - val_accuracy: 0.5694\n",
            "Epoch 148/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.7145 - accuracy: 0.7407 - val_loss: 1.3637 - val_accuracy: 0.5139\n",
            "Epoch 149/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.7563 - accuracy: 0.7238 - val_loss: 1.3326 - val_accuracy: 0.5417\n",
            "Epoch 150/500\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.7203 - accuracy: 0.7431 - val_loss: 1.3362 - val_accuracy: 0.5417\n",
            "Epoch 151/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.7246 - accuracy: 0.7369 - val_loss: 1.3474 - val_accuracy: 0.5208\n",
            "Epoch 152/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.7116 - accuracy: 0.7407 - val_loss: 1.4041 - val_accuracy: 0.5069\n",
            "Epoch 153/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.7072 - accuracy: 0.7384 - val_loss: 1.3242 - val_accuracy: 0.5486\n",
            "Epoch 154/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.6697 - accuracy: 0.7508 - val_loss: 1.2882 - val_accuracy: 0.5417\n",
            "Epoch 155/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.6896 - accuracy: 0.7500 - val_loss: 1.3160 - val_accuracy: 0.5139\n",
            "Epoch 156/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.6758 - accuracy: 0.7600 - val_loss: 1.2881 - val_accuracy: 0.5556\n",
            "Epoch 157/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.6732 - accuracy: 0.7662 - val_loss: 1.3477 - val_accuracy: 0.5347\n",
            "Epoch 158/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.6609 - accuracy: 0.7654 - val_loss: 1.4488 - val_accuracy: 0.4583\n",
            "Epoch 159/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.6911 - accuracy: 0.7539 - val_loss: 1.3152 - val_accuracy: 0.5764\n",
            "Epoch 160/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.6477 - accuracy: 0.7531 - val_loss: 1.3967 - val_accuracy: 0.5833\n",
            "Epoch 161/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.6779 - accuracy: 0.7554 - val_loss: 1.3382 - val_accuracy: 0.5347\n",
            "Epoch 162/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.6925 - accuracy: 0.7400 - val_loss: 1.3525 - val_accuracy: 0.5278\n",
            "Epoch 163/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.6706 - accuracy: 0.7554 - val_loss: 1.3111 - val_accuracy: 0.5764\n",
            "Epoch 164/500\n",
            "11/11 [==============================] - 0s 37ms/step - loss: 0.6788 - accuracy: 0.7515 - val_loss: 1.3127 - val_accuracy: 0.5694\n",
            "Epoch 165/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.6521 - accuracy: 0.7616 - val_loss: 1.4068 - val_accuracy: 0.5347\n",
            "Epoch 166/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.6739 - accuracy: 0.7515 - val_loss: 1.3357 - val_accuracy: 0.5556\n",
            "Epoch 167/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.6582 - accuracy: 0.7662 - val_loss: 1.3425 - val_accuracy: 0.5694\n",
            "Epoch 168/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.6464 - accuracy: 0.7724 - val_loss: 1.3356 - val_accuracy: 0.5625\n",
            "Epoch 169/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.6507 - accuracy: 0.7693 - val_loss: 1.3429 - val_accuracy: 0.5556\n",
            "Epoch 170/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.6202 - accuracy: 0.7724 - val_loss: 1.3642 - val_accuracy: 0.5556\n",
            "Epoch 171/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.6203 - accuracy: 0.7940 - val_loss: 1.3260 - val_accuracy: 0.5694\n",
            "Epoch 172/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.6301 - accuracy: 0.7747 - val_loss: 1.2625 - val_accuracy: 0.6042\n",
            "Epoch 173/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.6312 - accuracy: 0.7917 - val_loss: 1.3947 - val_accuracy: 0.5486\n",
            "Epoch 174/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.6052 - accuracy: 0.7909 - val_loss: 1.3307 - val_accuracy: 0.5625\n",
            "Epoch 175/500\n",
            "11/11 [==============================] - 0s 38ms/step - loss: 0.6161 - accuracy: 0.7801 - val_loss: 1.3442 - val_accuracy: 0.5486\n",
            "Epoch 176/500\n",
            "11/11 [==============================] - 0s 38ms/step - loss: 0.5864 - accuracy: 0.7955 - val_loss: 1.3381 - val_accuracy: 0.5625\n",
            "Epoch 177/500\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.5755 - accuracy: 0.7886 - val_loss: 1.3137 - val_accuracy: 0.5833\n",
            "Epoch 178/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.5782 - accuracy: 0.7955 - val_loss: 1.3348 - val_accuracy: 0.5556\n",
            "Epoch 179/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.5984 - accuracy: 0.7863 - val_loss: 1.3608 - val_accuracy: 0.5625\n",
            "Epoch 180/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.5645 - accuracy: 0.7978 - val_loss: 1.3393 - val_accuracy: 0.5347\n",
            "Epoch 181/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.5672 - accuracy: 0.8032 - val_loss: 1.2934 - val_accuracy: 0.5694\n",
            "Epoch 182/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.5587 - accuracy: 0.7863 - val_loss: 1.3398 - val_accuracy: 0.5486\n",
            "Epoch 183/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.5791 - accuracy: 0.7863 - val_loss: 1.3891 - val_accuracy: 0.5417\n",
            "Epoch 184/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.5811 - accuracy: 0.7901 - val_loss: 1.3637 - val_accuracy: 0.5417\n",
            "Epoch 185/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.5571 - accuracy: 0.8079 - val_loss: 1.2938 - val_accuracy: 0.5764\n",
            "Epoch 186/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.5518 - accuracy: 0.8086 - val_loss: 1.3367 - val_accuracy: 0.5417\n",
            "Epoch 187/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.5344 - accuracy: 0.8117 - val_loss: 1.3185 - val_accuracy: 0.5972\n",
            "Epoch 188/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.5480 - accuracy: 0.8094 - val_loss: 1.3217 - val_accuracy: 0.5625\n",
            "Epoch 189/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.5537 - accuracy: 0.7955 - val_loss: 1.3594 - val_accuracy: 0.5347\n",
            "Epoch 190/500\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.5297 - accuracy: 0.8202 - val_loss: 1.3116 - val_accuracy: 0.5417\n",
            "Epoch 191/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.5455 - accuracy: 0.8156 - val_loss: 1.3518 - val_accuracy: 0.5833\n",
            "Epoch 192/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.5455 - accuracy: 0.7971 - val_loss: 1.2943 - val_accuracy: 0.5486\n",
            "Epoch 193/500\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 0.5187 - accuracy: 0.8156 - val_loss: 1.3488 - val_accuracy: 0.5486\n",
            "Epoch 194/500\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.5106 - accuracy: 0.8171 - val_loss: 1.3791 - val_accuracy: 0.5556\n",
            "Epoch 195/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.5248 - accuracy: 0.8071 - val_loss: 1.2870 - val_accuracy: 0.5694\n",
            "Epoch 196/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.5250 - accuracy: 0.7978 - val_loss: 1.3031 - val_accuracy: 0.6042\n",
            "Epoch 197/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.5401 - accuracy: 0.8048 - val_loss: 1.2836 - val_accuracy: 0.5764\n",
            "Epoch 198/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.5298 - accuracy: 0.7963 - val_loss: 1.2823 - val_accuracy: 0.5972\n",
            "Epoch 199/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.5254 - accuracy: 0.8140 - val_loss: 1.4024 - val_accuracy: 0.5694\n",
            "Epoch 200/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.5246 - accuracy: 0.8164 - val_loss: 1.3435 - val_accuracy: 0.5833\n",
            "Epoch 201/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.5817 - accuracy: 0.7909 - val_loss: 1.4639 - val_accuracy: 0.5556\n",
            "Epoch 202/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.5573 - accuracy: 0.8125 - val_loss: 1.3821 - val_accuracy: 0.5903\n",
            "Epoch 203/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.5100 - accuracy: 0.8264 - val_loss: 1.3348 - val_accuracy: 0.5764\n",
            "Epoch 204/500\n",
            "11/11 [==============================] - 0s 38ms/step - loss: 0.5091 - accuracy: 0.8148 - val_loss: 1.3650 - val_accuracy: 0.5486\n",
            "Epoch 205/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.4709 - accuracy: 0.8387 - val_loss: 1.3595 - val_accuracy: 0.5625\n",
            "Epoch 206/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.4957 - accuracy: 0.8202 - val_loss: 1.2803 - val_accuracy: 0.5764\n",
            "Epoch 207/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.4825 - accuracy: 0.8403 - val_loss: 1.3520 - val_accuracy: 0.5694\n",
            "Epoch 208/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.4867 - accuracy: 0.8287 - val_loss: 1.3370 - val_accuracy: 0.5694\n",
            "Epoch 209/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.4567 - accuracy: 0.8480 - val_loss: 1.4055 - val_accuracy: 0.5694\n",
            "Epoch 210/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.4502 - accuracy: 0.8480 - val_loss: 1.3714 - val_accuracy: 0.5417\n",
            "Epoch 211/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.4515 - accuracy: 0.8465 - val_loss: 1.4166 - val_accuracy: 0.5625\n",
            "Epoch 212/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.4753 - accuracy: 0.8287 - val_loss: 1.3672 - val_accuracy: 0.5903\n",
            "Epoch 213/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.4886 - accuracy: 0.8326 - val_loss: 1.3691 - val_accuracy: 0.5694\n",
            "Epoch 214/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.5175 - accuracy: 0.8202 - val_loss: 1.3548 - val_accuracy: 0.5625\n",
            "Epoch 215/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.4708 - accuracy: 0.8318 - val_loss: 1.3583 - val_accuracy: 0.5556\n",
            "Epoch 216/500\n",
            "11/11 [==============================] - 0s 39ms/step - loss: 0.4727 - accuracy: 0.8310 - val_loss: 1.3454 - val_accuracy: 0.6111\n",
            "Epoch 217/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.4518 - accuracy: 0.8387 - val_loss: 1.3657 - val_accuracy: 0.5556\n",
            "Epoch 218/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.4542 - accuracy: 0.8495 - val_loss: 1.3376 - val_accuracy: 0.6042\n",
            "Epoch 219/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.4506 - accuracy: 0.8372 - val_loss: 1.3701 - val_accuracy: 0.5625\n",
            "Epoch 220/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.4460 - accuracy: 0.8434 - val_loss: 1.4020 - val_accuracy: 0.5347\n",
            "Epoch 221/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.4302 - accuracy: 0.8418 - val_loss: 1.4029 - val_accuracy: 0.6250\n",
            "Epoch 222/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.4580 - accuracy: 0.8526 - val_loss: 1.3489 - val_accuracy: 0.5694\n",
            "Epoch 223/500\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.4844 - accuracy: 0.8264 - val_loss: 1.3562 - val_accuracy: 0.5972\n",
            "Epoch 224/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.4872 - accuracy: 0.8202 - val_loss: 1.3260 - val_accuracy: 0.5556\n",
            "Epoch 225/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.4741 - accuracy: 0.8333 - val_loss: 1.3677 - val_accuracy: 0.5764\n",
            "Epoch 226/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.4668 - accuracy: 0.8372 - val_loss: 1.3457 - val_accuracy: 0.5764\n",
            "Epoch 227/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.4522 - accuracy: 0.8410 - val_loss: 1.3706 - val_accuracy: 0.5972\n",
            "Epoch 228/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.4124 - accuracy: 0.8619 - val_loss: 1.3515 - val_accuracy: 0.6042\n",
            "Epoch 229/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.4076 - accuracy: 0.8619 - val_loss: 1.3994 - val_accuracy: 0.5903\n",
            "Epoch 230/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.4160 - accuracy: 0.8426 - val_loss: 1.4255 - val_accuracy: 0.5625\n",
            "Epoch 231/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.4240 - accuracy: 0.8434 - val_loss: 1.4046 - val_accuracy: 0.5417\n",
            "Epoch 232/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.4345 - accuracy: 0.8457 - val_loss: 1.4224 - val_accuracy: 0.5486\n",
            "Epoch 233/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.4087 - accuracy: 0.8534 - val_loss: 1.4052 - val_accuracy: 0.5972\n",
            "Epoch 234/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.4060 - accuracy: 0.8596 - val_loss: 1.3811 - val_accuracy: 0.6111\n",
            "Epoch 235/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.4181 - accuracy: 0.8503 - val_loss: 1.3954 - val_accuracy: 0.5972\n",
            "Epoch 236/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.4155 - accuracy: 0.8588 - val_loss: 1.4227 - val_accuracy: 0.5625\n",
            "Epoch 237/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.3946 - accuracy: 0.8673 - val_loss: 1.3449 - val_accuracy: 0.5486\n",
            "Epoch 238/500\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 0.4270 - accuracy: 0.8480 - val_loss: 1.4905 - val_accuracy: 0.5833\n",
            "Epoch 239/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.3959 - accuracy: 0.8588 - val_loss: 1.3731 - val_accuracy: 0.5764\n",
            "Epoch 240/500\n",
            "11/11 [==============================] - 0s 38ms/step - loss: 0.3955 - accuracy: 0.8588 - val_loss: 1.4192 - val_accuracy: 0.6042\n",
            "Epoch 241/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.4209 - accuracy: 0.8480 - val_loss: 1.4381 - val_accuracy: 0.5903\n",
            "Epoch 242/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.3989 - accuracy: 0.8681 - val_loss: 1.3995 - val_accuracy: 0.5903\n",
            "Epoch 243/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.4099 - accuracy: 0.8573 - val_loss: 1.3465 - val_accuracy: 0.5694\n",
            "Epoch 244/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.4289 - accuracy: 0.8457 - val_loss: 1.4834 - val_accuracy: 0.5764\n",
            "Epoch 245/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.4077 - accuracy: 0.8573 - val_loss: 1.3494 - val_accuracy: 0.5764\n",
            "Epoch 246/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.3886 - accuracy: 0.8657 - val_loss: 1.3638 - val_accuracy: 0.6042\n",
            "Epoch 247/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.3644 - accuracy: 0.8696 - val_loss: 1.4404 - val_accuracy: 0.5833\n",
            "Epoch 248/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.3785 - accuracy: 0.8719 - val_loss: 1.3914 - val_accuracy: 0.5972\n",
            "Epoch 249/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.3678 - accuracy: 0.8789 - val_loss: 1.4447 - val_accuracy: 0.5903\n",
            "Epoch 250/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.3951 - accuracy: 0.8580 - val_loss: 1.4373 - val_accuracy: 0.5764\n",
            "Epoch 251/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.3540 - accuracy: 0.8804 - val_loss: 1.4461 - val_accuracy: 0.5903\n",
            "Epoch 252/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.3436 - accuracy: 0.8904 - val_loss: 1.4244 - val_accuracy: 0.5694\n",
            "Epoch 253/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.3709 - accuracy: 0.8704 - val_loss: 1.5160 - val_accuracy: 0.5694\n",
            "Epoch 254/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.3787 - accuracy: 0.8557 - val_loss: 1.3903 - val_accuracy: 0.6042\n",
            "Epoch 255/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.3557 - accuracy: 0.8673 - val_loss: 1.4127 - val_accuracy: 0.6111\n",
            "Epoch 256/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.3625 - accuracy: 0.8704 - val_loss: 1.4096 - val_accuracy: 0.6111\n",
            "Epoch 257/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.3437 - accuracy: 0.8873 - val_loss: 1.4768 - val_accuracy: 0.5833\n",
            "Epoch 258/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.3967 - accuracy: 0.8611 - val_loss: 1.3630 - val_accuracy: 0.6250\n",
            "Epoch 259/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.3786 - accuracy: 0.8696 - val_loss: 1.4655 - val_accuracy: 0.5764\n",
            "Epoch 260/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.3652 - accuracy: 0.8719 - val_loss: 1.4063 - val_accuracy: 0.6042\n",
            "Epoch 261/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.3681 - accuracy: 0.8773 - val_loss: 1.4156 - val_accuracy: 0.5903\n",
            "Epoch 262/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.3435 - accuracy: 0.8819 - val_loss: 1.3289 - val_accuracy: 0.5486\n",
            "Epoch 263/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.3667 - accuracy: 0.8750 - val_loss: 1.4850 - val_accuracy: 0.6181\n",
            "Epoch 264/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.3286 - accuracy: 0.8835 - val_loss: 1.5325 - val_accuracy: 0.5694\n",
            "Epoch 265/500\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.3570 - accuracy: 0.8789 - val_loss: 1.4957 - val_accuracy: 0.5833\n",
            "Epoch 266/500\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 0.3709 - accuracy: 0.8796 - val_loss: 1.4157 - val_accuracy: 0.5625\n",
            "Epoch 267/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.3604 - accuracy: 0.8750 - val_loss: 1.4293 - val_accuracy: 0.5833\n",
            "Epoch 268/500\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 0.3292 - accuracy: 0.8843 - val_loss: 1.4282 - val_accuracy: 0.6181\n",
            "Epoch 269/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.3329 - accuracy: 0.8796 - val_loss: 1.4703 - val_accuracy: 0.6181\n",
            "Epoch 270/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.3302 - accuracy: 0.8881 - val_loss: 1.4725 - val_accuracy: 0.6389\n",
            "Epoch 271/500\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.3511 - accuracy: 0.8727 - val_loss: 1.5113 - val_accuracy: 0.6042\n",
            "Epoch 272/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.3362 - accuracy: 0.8835 - val_loss: 1.4654 - val_accuracy: 0.6042\n",
            "Epoch 273/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.2942 - accuracy: 0.9005 - val_loss: 1.4892 - val_accuracy: 0.6111\n",
            "Epoch 274/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.3001 - accuracy: 0.9020 - val_loss: 1.4748 - val_accuracy: 0.6181\n",
            "Epoch 275/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.3439 - accuracy: 0.8796 - val_loss: 1.4520 - val_accuracy: 0.6042\n",
            "Epoch 276/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.3202 - accuracy: 0.8997 - val_loss: 1.4935 - val_accuracy: 0.5903\n",
            "Epoch 277/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.3533 - accuracy: 0.8727 - val_loss: 1.5146 - val_accuracy: 0.5694\n",
            "Epoch 278/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.3099 - accuracy: 0.8958 - val_loss: 1.5026 - val_accuracy: 0.6111\n",
            "Epoch 279/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.3372 - accuracy: 0.8765 - val_loss: 1.4508 - val_accuracy: 0.6042\n",
            "Epoch 280/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.3192 - accuracy: 0.8920 - val_loss: 1.4038 - val_accuracy: 0.5694\n",
            "Epoch 281/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.3055 - accuracy: 0.9043 - val_loss: 1.3864 - val_accuracy: 0.6389\n",
            "Epoch 282/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.3272 - accuracy: 0.8920 - val_loss: 1.5668 - val_accuracy: 0.6042\n",
            "Epoch 283/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.3517 - accuracy: 0.8850 - val_loss: 1.4169 - val_accuracy: 0.6111\n",
            "Epoch 284/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.3213 - accuracy: 0.8897 - val_loss: 1.5442 - val_accuracy: 0.5903\n",
            "Epoch 285/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.3129 - accuracy: 0.8927 - val_loss: 1.4608 - val_accuracy: 0.5903\n",
            "Epoch 286/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.2985 - accuracy: 0.8974 - val_loss: 1.4809 - val_accuracy: 0.6111\n",
            "Epoch 287/500\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.2911 - accuracy: 0.9035 - val_loss: 1.4551 - val_accuracy: 0.6111\n",
            "Epoch 288/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.2804 - accuracy: 0.9043 - val_loss: 1.4719 - val_accuracy: 0.6319\n",
            "Epoch 289/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.3205 - accuracy: 0.8904 - val_loss: 1.5378 - val_accuracy: 0.5972\n",
            "Epoch 290/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.2775 - accuracy: 0.9043 - val_loss: 1.3831 - val_accuracy: 0.6389\n",
            "Epoch 291/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.3115 - accuracy: 0.8935 - val_loss: 1.5039 - val_accuracy: 0.5694\n",
            "Epoch 292/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.2864 - accuracy: 0.8981 - val_loss: 1.4080 - val_accuracy: 0.6181\n",
            "Epoch 293/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.2930 - accuracy: 0.8997 - val_loss: 1.5283 - val_accuracy: 0.5625\n",
            "Epoch 294/500\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.2860 - accuracy: 0.9028 - val_loss: 1.3934 - val_accuracy: 0.5972\n",
            "Epoch 295/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.2816 - accuracy: 0.9144 - val_loss: 1.4831 - val_accuracy: 0.5972\n",
            "Epoch 296/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.2665 - accuracy: 0.9144 - val_loss: 1.4443 - val_accuracy: 0.6111\n",
            "Epoch 297/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.2833 - accuracy: 0.9012 - val_loss: 1.4799 - val_accuracy: 0.6042\n",
            "Epoch 298/500\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.2607 - accuracy: 0.9120 - val_loss: 1.5365 - val_accuracy: 0.5972\n",
            "Epoch 299/500\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.2822 - accuracy: 0.9028 - val_loss: 1.5003 - val_accuracy: 0.6042\n",
            "Epoch 300/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.2755 - accuracy: 0.8974 - val_loss: 1.4482 - val_accuracy: 0.6181\n",
            "Epoch 301/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.2813 - accuracy: 0.9051 - val_loss: 1.4964 - val_accuracy: 0.5833\n",
            "Epoch 302/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.3205 - accuracy: 0.8912 - val_loss: 1.4679 - val_accuracy: 0.6181\n",
            "Epoch 303/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.3036 - accuracy: 0.8812 - val_loss: 1.5207 - val_accuracy: 0.5972\n",
            "Epoch 304/500\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.2844 - accuracy: 0.9005 - val_loss: 1.5239 - val_accuracy: 0.6111\n",
            "Epoch 305/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.2680 - accuracy: 0.9074 - val_loss: 1.5058 - val_accuracy: 0.6111\n",
            "Epoch 306/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.2758 - accuracy: 0.9066 - val_loss: 1.5168 - val_accuracy: 0.6250\n",
            "Epoch 307/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.2866 - accuracy: 0.9051 - val_loss: 1.4572 - val_accuracy: 0.6111\n",
            "Epoch 308/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.2564 - accuracy: 0.9090 - val_loss: 1.5354 - val_accuracy: 0.6250\n",
            "Epoch 309/500\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.2875 - accuracy: 0.9020 - val_loss: 1.4953 - val_accuracy: 0.5833\n",
            "Epoch 310/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.2913 - accuracy: 0.8912 - val_loss: 1.4754 - val_accuracy: 0.5972\n",
            "Epoch 311/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.2888 - accuracy: 0.9012 - val_loss: 1.5707 - val_accuracy: 0.6111\n",
            "Epoch 312/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.2837 - accuracy: 0.8989 - val_loss: 1.4866 - val_accuracy: 0.6389\n",
            "Epoch 313/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.2673 - accuracy: 0.9090 - val_loss: 1.4817 - val_accuracy: 0.6042\n",
            "Epoch 314/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.2635 - accuracy: 0.9151 - val_loss: 1.5849 - val_accuracy: 0.6181\n",
            "Epoch 315/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.2418 - accuracy: 0.9144 - val_loss: 1.5568 - val_accuracy: 0.5903\n",
            "Epoch 316/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.2916 - accuracy: 0.8974 - val_loss: 1.5165 - val_accuracy: 0.6319\n",
            "Epoch 317/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.2640 - accuracy: 0.9144 - val_loss: 1.6135 - val_accuracy: 0.5694\n",
            "Epoch 318/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.3082 - accuracy: 0.8904 - val_loss: 1.6597 - val_accuracy: 0.5694\n",
            "Epoch 319/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.2830 - accuracy: 0.8997 - val_loss: 1.6076 - val_accuracy: 0.5903\n",
            "Epoch 320/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.2875 - accuracy: 0.8920 - val_loss: 1.5885 - val_accuracy: 0.5694\n",
            "Epoch 321/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.2743 - accuracy: 0.9012 - val_loss: 1.6749 - val_accuracy: 0.5417\n",
            "Epoch 322/500\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.2578 - accuracy: 0.9097 - val_loss: 1.5986 - val_accuracy: 0.6042\n",
            "Epoch 323/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.2487 - accuracy: 0.9113 - val_loss: 1.6035 - val_accuracy: 0.5764\n",
            "Epoch 324/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.2491 - accuracy: 0.9167 - val_loss: 1.6026 - val_accuracy: 0.5833\n",
            "Epoch 325/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.2449 - accuracy: 0.9159 - val_loss: 1.5828 - val_accuracy: 0.6181\n",
            "Epoch 326/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.2654 - accuracy: 0.9097 - val_loss: 1.5786 - val_accuracy: 0.6111\n",
            "Epoch 327/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.2413 - accuracy: 0.9128 - val_loss: 1.5666 - val_accuracy: 0.6597\n",
            "Epoch 328/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.2162 - accuracy: 0.9306 - val_loss: 1.5555 - val_accuracy: 0.6181\n",
            "Epoch 329/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.2310 - accuracy: 0.9190 - val_loss: 1.5516 - val_accuracy: 0.6111\n",
            "Epoch 330/500\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 0.2462 - accuracy: 0.9159 - val_loss: 1.5392 - val_accuracy: 0.6250\n",
            "Epoch 331/500\n",
            "11/11 [==============================] - 0s 38ms/step - loss: 0.2342 - accuracy: 0.9113 - val_loss: 1.5351 - val_accuracy: 0.5833\n",
            "Epoch 332/500\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.2580 - accuracy: 0.9128 - val_loss: 1.6359 - val_accuracy: 0.5764\n",
            "Epoch 333/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.2813 - accuracy: 0.8981 - val_loss: 1.5519 - val_accuracy: 0.6389\n",
            "Epoch 334/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.2633 - accuracy: 0.9082 - val_loss: 1.5362 - val_accuracy: 0.5903\n",
            "Epoch 335/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.2437 - accuracy: 0.9213 - val_loss: 1.4680 - val_accuracy: 0.6250\n",
            "Epoch 336/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.2361 - accuracy: 0.9182 - val_loss: 1.6031 - val_accuracy: 0.5833\n",
            "Epoch 337/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.2242 - accuracy: 0.9282 - val_loss: 1.5314 - val_accuracy: 0.6389\n",
            "Epoch 338/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.2442 - accuracy: 0.9182 - val_loss: 1.4634 - val_accuracy: 0.6389\n",
            "Epoch 339/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.2018 - accuracy: 0.9367 - val_loss: 1.5421 - val_accuracy: 0.6042\n",
            "Epoch 340/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.2482 - accuracy: 0.9082 - val_loss: 1.6240 - val_accuracy: 0.6181\n",
            "Epoch 341/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.2383 - accuracy: 0.9205 - val_loss: 1.5853 - val_accuracy: 0.5903\n",
            "Epoch 342/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.2154 - accuracy: 0.9236 - val_loss: 1.6243 - val_accuracy: 0.5903\n",
            "Epoch 343/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.2338 - accuracy: 0.9221 - val_loss: 1.6388 - val_accuracy: 0.5903\n",
            "Epoch 344/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.2445 - accuracy: 0.9090 - val_loss: 1.6417 - val_accuracy: 0.5833\n",
            "Epoch 345/500\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 0.2222 - accuracy: 0.9190 - val_loss: 1.6202 - val_accuracy: 0.6111\n",
            "Epoch 346/500\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.2335 - accuracy: 0.9282 - val_loss: 1.5827 - val_accuracy: 0.5972\n",
            "Epoch 347/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.2511 - accuracy: 0.9136 - val_loss: 1.5823 - val_accuracy: 0.5556\n",
            "Epoch 348/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.2209 - accuracy: 0.9275 - val_loss: 1.5414 - val_accuracy: 0.6250\n",
            "Epoch 349/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.2562 - accuracy: 0.9074 - val_loss: 1.5576 - val_accuracy: 0.6250\n",
            "Epoch 350/500\n",
            "11/11 [==============================] - 0s 37ms/step - loss: 0.2162 - accuracy: 0.9267 - val_loss: 1.5188 - val_accuracy: 0.6528\n",
            "Epoch 351/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.2209 - accuracy: 0.9298 - val_loss: 1.5311 - val_accuracy: 0.6250\n",
            "Epoch 352/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.2118 - accuracy: 0.9159 - val_loss: 1.5905 - val_accuracy: 0.6111\n",
            "Epoch 353/500\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.2294 - accuracy: 0.9267 - val_loss: 1.5903 - val_accuracy: 0.6319\n",
            "Epoch 354/500\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.2568 - accuracy: 0.9136 - val_loss: 1.7032 - val_accuracy: 0.5972\n",
            "Epoch 355/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.2254 - accuracy: 0.9198 - val_loss: 1.6587 - val_accuracy: 0.5972\n",
            "Epoch 356/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.2116 - accuracy: 0.9221 - val_loss: 1.7298 - val_accuracy: 0.6181\n",
            "Epoch 357/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.2690 - accuracy: 0.9128 - val_loss: 1.7428 - val_accuracy: 0.6250\n",
            "Epoch 358/500\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.2499 - accuracy: 0.9159 - val_loss: 1.6422 - val_accuracy: 0.6181\n",
            "Epoch 359/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.2374 - accuracy: 0.9198 - val_loss: 1.5933 - val_accuracy: 0.6597\n",
            "Epoch 360/500\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.2043 - accuracy: 0.9321 - val_loss: 1.6710 - val_accuracy: 0.6181\n",
            "Epoch 361/500\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.2183 - accuracy: 0.9336 - val_loss: 1.6605 - val_accuracy: 0.6319\n",
            "Epoch 362/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.2415 - accuracy: 0.9213 - val_loss: 1.6164 - val_accuracy: 0.6111\n",
            "Epoch 363/500\n",
            "11/11 [==============================] - 0s 37ms/step - loss: 0.2336 - accuracy: 0.9182 - val_loss: 1.7148 - val_accuracy: 0.5903\n",
            "Epoch 364/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.2031 - accuracy: 0.9336 - val_loss: 1.6422 - val_accuracy: 0.6042\n",
            "Epoch 365/500\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.2135 - accuracy: 0.9198 - val_loss: 1.6410 - val_accuracy: 0.5764\n",
            "Epoch 366/500\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 0.2006 - accuracy: 0.9306 - val_loss: 1.6180 - val_accuracy: 0.6111\n",
            "Epoch 367/500\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.2043 - accuracy: 0.9298 - val_loss: 1.7137 - val_accuracy: 0.6250\n",
            "Epoch 368/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.2310 - accuracy: 0.9190 - val_loss: 1.6528 - val_accuracy: 0.6389\n",
            "Epoch 369/500\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 0.1888 - accuracy: 0.9352 - val_loss: 1.7065 - val_accuracy: 0.6181\n",
            "Epoch 370/500\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.1948 - accuracy: 0.9344 - val_loss: 1.6261 - val_accuracy: 0.6181\n",
            "Epoch 371/500\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 0.2325 - accuracy: 0.9252 - val_loss: 1.7214 - val_accuracy: 0.6042\n",
            "Epoch 372/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.2023 - accuracy: 0.9360 - val_loss: 1.6945 - val_accuracy: 0.6111\n",
            "Epoch 373/500\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.1938 - accuracy: 0.9360 - val_loss: 1.6762 - val_accuracy: 0.6181\n",
            "Epoch 374/500\n",
            "11/11 [==============================] - 0s 38ms/step - loss: 0.2042 - accuracy: 0.9313 - val_loss: 1.7458 - val_accuracy: 0.6042\n",
            "Epoch 375/500\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 0.1929 - accuracy: 0.9344 - val_loss: 1.7505 - val_accuracy: 0.6181\n",
            "Epoch 376/500\n",
            "11/11 [==============================] - 0s 37ms/step - loss: 0.2263 - accuracy: 0.9213 - val_loss: 1.7543 - val_accuracy: 0.5972\n",
            "Epoch 377/500\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 0.2074 - accuracy: 0.9306 - val_loss: 1.7567 - val_accuracy: 0.5903\n",
            "Epoch 378/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.1985 - accuracy: 0.9313 - val_loss: 1.6992 - val_accuracy: 0.6181\n",
            "Epoch 379/500\n",
            "11/11 [==============================] - 0s 37ms/step - loss: 0.1941 - accuracy: 0.9352 - val_loss: 1.6722 - val_accuracy: 0.6042\n",
            "Epoch 380/500\n",
            "11/11 [==============================] - 0s 40ms/step - loss: 0.1954 - accuracy: 0.9352 - val_loss: 1.7312 - val_accuracy: 0.6319\n",
            "Epoch 381/500\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 0.2025 - accuracy: 0.9313 - val_loss: 1.6796 - val_accuracy: 0.6111\n",
            "Epoch 382/500\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.2000 - accuracy: 0.9259 - val_loss: 1.6845 - val_accuracy: 0.6111\n",
            "Epoch 383/500\n",
            "11/11 [==============================] - 0s 43ms/step - loss: 0.2153 - accuracy: 0.9282 - val_loss: 1.6240 - val_accuracy: 0.6250\n",
            "Epoch 384/500\n",
            "11/11 [==============================] - 1s 46ms/step - loss: 0.2162 - accuracy: 0.9252 - val_loss: 1.7165 - val_accuracy: 0.5972\n",
            "Epoch 385/500\n",
            "11/11 [==============================] - 0s 37ms/step - loss: 0.1781 - accuracy: 0.9468 - val_loss: 1.6426 - val_accuracy: 0.6319\n",
            "Epoch 386/500\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.2104 - accuracy: 0.9306 - val_loss: 1.6665 - val_accuracy: 0.6319\n",
            "Epoch 387/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.2041 - accuracy: 0.9306 - val_loss: 1.6427 - val_accuracy: 0.6319\n",
            "Epoch 388/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.2103 - accuracy: 0.9267 - val_loss: 1.6823 - val_accuracy: 0.6250\n",
            "Epoch 389/500\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.1863 - accuracy: 0.9437 - val_loss: 1.6844 - val_accuracy: 0.6181\n",
            "Epoch 390/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.1705 - accuracy: 0.9398 - val_loss: 1.6170 - val_accuracy: 0.5972\n",
            "Epoch 391/500\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.1897 - accuracy: 0.9367 - val_loss: 1.7732 - val_accuracy: 0.6111\n",
            "Epoch 392/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.1951 - accuracy: 0.9336 - val_loss: 1.6748 - val_accuracy: 0.6181\n",
            "Epoch 393/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.1735 - accuracy: 0.9460 - val_loss: 1.7185 - val_accuracy: 0.6250\n",
            "Epoch 394/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.1726 - accuracy: 0.9383 - val_loss: 1.7258 - val_accuracy: 0.6181\n",
            "Epoch 395/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.1632 - accuracy: 0.9498 - val_loss: 1.6657 - val_accuracy: 0.6250\n",
            "Epoch 396/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.1753 - accuracy: 0.9429 - val_loss: 1.6531 - val_accuracy: 0.6389\n",
            "Epoch 397/500\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.1946 - accuracy: 0.9367 - val_loss: 1.7442 - val_accuracy: 0.6250\n",
            "Epoch 398/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.1661 - accuracy: 0.9429 - val_loss: 1.6377 - val_accuracy: 0.6181\n",
            "Epoch 399/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.1691 - accuracy: 0.9498 - val_loss: 1.6651 - val_accuracy: 0.6319\n",
            "Epoch 400/500\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 0.1830 - accuracy: 0.9352 - val_loss: 1.6631 - val_accuracy: 0.6319\n",
            "Epoch 401/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.1932 - accuracy: 0.9360 - val_loss: 1.7296 - val_accuracy: 0.6458\n",
            "Epoch 402/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.1727 - accuracy: 0.9383 - val_loss: 1.7059 - val_accuracy: 0.6250\n",
            "Epoch 403/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.2190 - accuracy: 0.9236 - val_loss: 1.6473 - val_accuracy: 0.6458\n",
            "Epoch 404/500\n",
            "11/11 [==============================] - 0s 38ms/step - loss: 0.1610 - accuracy: 0.9468 - val_loss: 1.6750 - val_accuracy: 0.6181\n",
            "Epoch 405/500\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.1674 - accuracy: 0.9452 - val_loss: 1.6904 - val_accuracy: 0.6250\n",
            "Epoch 406/500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.1638 - accuracy: 0.9375 - val_loss: 1.6658 - val_accuracy: 0.6597\n",
            "Epoch 407/500\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 0.1733 - accuracy: 0.9344 - val_loss: 1.6283 - val_accuracy: 0.6736\n",
            "Epoch 408/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.1777 - accuracy: 0.9414 - val_loss: 1.6523 - val_accuracy: 0.6528\n",
            "Epoch 409/500\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 0.1725 - accuracy: 0.9414 - val_loss: 1.7016 - val_accuracy: 0.6111\n",
            "Epoch 410/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.1733 - accuracy: 0.9429 - val_loss: 1.6515 - val_accuracy: 0.6319\n",
            "Epoch 411/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.1615 - accuracy: 0.9383 - val_loss: 1.6655 - val_accuracy: 0.6111\n",
            "Epoch 412/500\n",
            "11/11 [==============================] - 0s 37ms/step - loss: 0.1724 - accuracy: 0.9414 - val_loss: 1.7893 - val_accuracy: 0.5972\n",
            "Epoch 413/500\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 0.1695 - accuracy: 0.9398 - val_loss: 1.7349 - val_accuracy: 0.5972\n",
            "Epoch 414/500\n",
            "11/11 [==============================] - 0s 37ms/step - loss: 0.1660 - accuracy: 0.9506 - val_loss: 1.7543 - val_accuracy: 0.6319\n",
            "Epoch 415/500\n",
            "11/11 [==============================] - 0s 38ms/step - loss: 0.1562 - accuracy: 0.9522 - val_loss: 1.7826 - val_accuracy: 0.5972\n",
            "Epoch 416/500\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.1434 - accuracy: 0.9576 - val_loss: 1.7139 - val_accuracy: 0.6319\n",
            "Epoch 417/500\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 0.1651 - accuracy: 0.9460 - val_loss: 1.7159 - val_accuracy: 0.6389\n",
            "Epoch 418/500\n",
            "11/11 [==============================] - 0s 38ms/step - loss: 0.1854 - accuracy: 0.9360 - val_loss: 1.6736 - val_accuracy: 0.6042\n",
            "Epoch 419/500\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 0.1989 - accuracy: 0.9329 - val_loss: 1.6592 - val_accuracy: 0.6181\n",
            "Epoch 420/500\n",
            "11/11 [==============================] - 0s 37ms/step - loss: 0.2040 - accuracy: 0.9267 - val_loss: 1.6911 - val_accuracy: 0.6111\n",
            "Epoch 421/500\n",
            "11/11 [==============================] - 0s 37ms/step - loss: 0.1846 - accuracy: 0.9444 - val_loss: 1.7366 - val_accuracy: 0.5903\n",
            "Epoch 422/500\n",
            "11/11 [==============================] - 0s 37ms/step - loss: 0.1886 - accuracy: 0.9360 - val_loss: 1.8630 - val_accuracy: 0.6181\n",
            "Epoch 423/500\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.1786 - accuracy: 0.9352 - val_loss: 1.7221 - val_accuracy: 0.6250\n",
            "Epoch 424/500\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.1834 - accuracy: 0.9336 - val_loss: 1.7764 - val_accuracy: 0.6319\n",
            "Epoch 425/500\n",
            "11/11 [==============================] - 0s 39ms/step - loss: 0.1761 - accuracy: 0.9383 - val_loss: 1.8003 - val_accuracy: 0.6389\n",
            "Epoch 426/500\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.1866 - accuracy: 0.9421 - val_loss: 1.7614 - val_accuracy: 0.6042\n",
            "Epoch 427/500\n",
            "11/11 [==============================] - 0s 37ms/step - loss: 0.1500 - accuracy: 0.9522 - val_loss: 1.8351 - val_accuracy: 0.6042\n",
            "Epoch 428/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.1721 - accuracy: 0.9429 - val_loss: 1.7871 - val_accuracy: 0.5972\n",
            "Epoch 429/500\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.1944 - accuracy: 0.9336 - val_loss: 1.7791 - val_accuracy: 0.6389\n",
            "Epoch 430/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.1690 - accuracy: 0.9367 - val_loss: 1.8472 - val_accuracy: 0.6111\n",
            "Epoch 431/500\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 0.1545 - accuracy: 0.9421 - val_loss: 1.7072 - val_accuracy: 0.6042\n",
            "Epoch 432/500\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.1660 - accuracy: 0.9514 - val_loss: 1.7914 - val_accuracy: 0.6319\n",
            "Epoch 433/500\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.1749 - accuracy: 0.9406 - val_loss: 1.7912 - val_accuracy: 0.6250\n",
            "Epoch 434/500\n",
            "11/11 [==============================] - 0s 39ms/step - loss: 0.1546 - accuracy: 0.9437 - val_loss: 1.7138 - val_accuracy: 0.6528\n",
            "Epoch 435/500\n",
            "11/11 [==============================] - 0s 39ms/step - loss: 0.1625 - accuracy: 0.9491 - val_loss: 1.6678 - val_accuracy: 0.6458\n",
            "Epoch 436/500\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.1493 - accuracy: 0.9460 - val_loss: 1.7148 - val_accuracy: 0.6111\n",
            "Epoch 437/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.1718 - accuracy: 0.9390 - val_loss: 1.7501 - val_accuracy: 0.6389\n",
            "Epoch 438/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.1394 - accuracy: 0.9576 - val_loss: 1.8179 - val_accuracy: 0.6111\n",
            "Epoch 439/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.1519 - accuracy: 0.9568 - val_loss: 1.6908 - val_accuracy: 0.6389\n",
            "Epoch 440/500\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.1604 - accuracy: 0.9444 - val_loss: 1.7854 - val_accuracy: 0.6528\n",
            "Epoch 441/500\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 0.1495 - accuracy: 0.9483 - val_loss: 1.8491 - val_accuracy: 0.6389\n",
            "Epoch 442/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.1650 - accuracy: 0.9421 - val_loss: 1.6617 - val_accuracy: 0.6458\n",
            "Epoch 443/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.1865 - accuracy: 0.9398 - val_loss: 1.6469 - val_accuracy: 0.6389\n",
            "Epoch 444/500\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.1727 - accuracy: 0.9429 - val_loss: 1.7909 - val_accuracy: 0.6250\n",
            "Epoch 445/500\n",
            "11/11 [==============================] - 0s 37ms/step - loss: 0.1422 - accuracy: 0.9583 - val_loss: 1.6543 - val_accuracy: 0.6597\n",
            "Epoch 446/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.1222 - accuracy: 0.9622 - val_loss: 1.7521 - val_accuracy: 0.6736\n",
            "Epoch 447/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.1329 - accuracy: 0.9583 - val_loss: 1.7117 - val_accuracy: 0.6528\n",
            "Epoch 448/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.1436 - accuracy: 0.9560 - val_loss: 1.6716 - val_accuracy: 0.6597\n",
            "Epoch 449/500\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 0.1588 - accuracy: 0.9475 - val_loss: 1.6342 - val_accuracy: 0.6528\n",
            "Epoch 450/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.1607 - accuracy: 0.9475 - val_loss: 1.6622 - val_accuracy: 0.6528\n",
            "Epoch 451/500\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.1611 - accuracy: 0.9498 - val_loss: 1.6646 - val_accuracy: 0.6458\n",
            "Epoch 452/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.1606 - accuracy: 0.9398 - val_loss: 1.7257 - val_accuracy: 0.6389\n",
            "Epoch 453/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.1504 - accuracy: 0.9506 - val_loss: 1.7551 - val_accuracy: 0.6458\n",
            "Epoch 454/500\n",
            "11/11 [==============================] - 0s 40ms/step - loss: 0.1524 - accuracy: 0.9529 - val_loss: 1.6726 - val_accuracy: 0.6528\n",
            "Epoch 455/500\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.1561 - accuracy: 0.9491 - val_loss: 1.6593 - val_accuracy: 0.6667\n",
            "Epoch 456/500\n",
            "11/11 [==============================] - 0s 39ms/step - loss: 0.1591 - accuracy: 0.9491 - val_loss: 1.7741 - val_accuracy: 0.6389\n",
            "Epoch 457/500\n",
            "11/11 [==============================] - 0s 37ms/step - loss: 0.1584 - accuracy: 0.9491 - val_loss: 1.7752 - val_accuracy: 0.6319\n",
            "Epoch 458/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.1303 - accuracy: 0.9552 - val_loss: 1.6981 - val_accuracy: 0.6528\n",
            "Epoch 459/500\n",
            "11/11 [==============================] - 0s 38ms/step - loss: 0.1348 - accuracy: 0.9522 - val_loss: 1.8707 - val_accuracy: 0.6250\n",
            "Epoch 460/500\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.1458 - accuracy: 0.9545 - val_loss: 1.7861 - val_accuracy: 0.6458\n",
            "Epoch 461/500\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 0.1344 - accuracy: 0.9498 - val_loss: 1.9262 - val_accuracy: 0.6528\n",
            "Epoch 462/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.1335 - accuracy: 0.9537 - val_loss: 1.7135 - val_accuracy: 0.6597\n",
            "Epoch 463/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.1218 - accuracy: 0.9576 - val_loss: 1.7346 - val_accuracy: 0.6736\n",
            "Epoch 464/500\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 0.1365 - accuracy: 0.9560 - val_loss: 1.7011 - val_accuracy: 0.6528\n",
            "Epoch 465/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.1449 - accuracy: 0.9483 - val_loss: 1.8849 - val_accuracy: 0.6319\n",
            "Epoch 466/500\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.1341 - accuracy: 0.9552 - val_loss: 1.7036 - val_accuracy: 0.6458\n",
            "Epoch 467/500\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.1321 - accuracy: 0.9576 - val_loss: 1.7550 - val_accuracy: 0.6806\n",
            "Epoch 468/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.1364 - accuracy: 0.9545 - val_loss: 1.7410 - val_accuracy: 0.6528\n",
            "Epoch 469/500\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 0.1381 - accuracy: 0.9637 - val_loss: 1.8624 - val_accuracy: 0.6458\n",
            "Epoch 470/500\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.1536 - accuracy: 0.9483 - val_loss: 1.7258 - val_accuracy: 0.6389\n",
            "Epoch 471/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.1377 - accuracy: 0.9506 - val_loss: 1.8281 - val_accuracy: 0.6597\n",
            "Epoch 472/500\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 0.1439 - accuracy: 0.9576 - val_loss: 1.7337 - val_accuracy: 0.6458\n",
            "Epoch 473/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.1132 - accuracy: 0.9622 - val_loss: 1.8369 - val_accuracy: 0.6528\n",
            "Epoch 474/500\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 0.1340 - accuracy: 0.9552 - val_loss: 1.8632 - val_accuracy: 0.6319\n",
            "Epoch 475/500\n",
            "11/11 [==============================] - 0s 38ms/step - loss: 0.1716 - accuracy: 0.9352 - val_loss: 1.7337 - val_accuracy: 0.6528\n",
            "Epoch 476/500\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 0.1206 - accuracy: 0.9599 - val_loss: 1.8070 - val_accuracy: 0.6389\n",
            "Epoch 477/500\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.1340 - accuracy: 0.9545 - val_loss: 1.7554 - val_accuracy: 0.6528\n",
            "Epoch 478/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.1460 - accuracy: 0.9491 - val_loss: 1.8880 - val_accuracy: 0.6250\n",
            "Epoch 479/500\n",
            "11/11 [==============================] - 0s 37ms/step - loss: 0.1802 - accuracy: 0.9329 - val_loss: 1.7089 - val_accuracy: 0.6806\n",
            "Epoch 480/500\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.1464 - accuracy: 0.9514 - val_loss: 1.6734 - val_accuracy: 0.6458\n",
            "Epoch 481/500\n",
            "11/11 [==============================] - 0s 38ms/step - loss: 0.1512 - accuracy: 0.9506 - val_loss: 1.8193 - val_accuracy: 0.6319\n",
            "Epoch 482/500\n",
            "11/11 [==============================] - 0s 39ms/step - loss: 0.1309 - accuracy: 0.9606 - val_loss: 1.7649 - val_accuracy: 0.6528\n",
            "Epoch 483/500\n",
            "11/11 [==============================] - 0s 43ms/step - loss: 0.1387 - accuracy: 0.9552 - val_loss: 1.8355 - val_accuracy: 0.6458\n",
            "Epoch 484/500\n",
            "11/11 [==============================] - 0s 38ms/step - loss: 0.1124 - accuracy: 0.9668 - val_loss: 1.8626 - val_accuracy: 0.6597\n",
            "Epoch 485/500\n",
            "11/11 [==============================] - 0s 40ms/step - loss: 0.1136 - accuracy: 0.9637 - val_loss: 1.9495 - val_accuracy: 0.6319\n",
            "Epoch 486/500\n",
            "11/11 [==============================] - 0s 39ms/step - loss: 0.1318 - accuracy: 0.9537 - val_loss: 1.8555 - val_accuracy: 0.6597\n",
            "Epoch 487/500\n",
            "11/11 [==============================] - 0s 37ms/step - loss: 0.1525 - accuracy: 0.9444 - val_loss: 1.8931 - val_accuracy: 0.6389\n",
            "Epoch 488/500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.1336 - accuracy: 0.9568 - val_loss: 1.8865 - val_accuracy: 0.6389\n",
            "Epoch 489/500\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 0.1463 - accuracy: 0.9475 - val_loss: 2.0189 - val_accuracy: 0.5903\n",
            "Epoch 490/500\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.1118 - accuracy: 0.9684 - val_loss: 1.9536 - val_accuracy: 0.6181\n",
            "Epoch 491/500\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 0.1598 - accuracy: 0.9414 - val_loss: 1.9047 - val_accuracy: 0.6458\n",
            "Epoch 492/500\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.1543 - accuracy: 0.9475 - val_loss: 1.8980 - val_accuracy: 0.6319\n",
            "Epoch 493/500\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.1596 - accuracy: 0.9437 - val_loss: 1.8548 - val_accuracy: 0.6250\n",
            "Epoch 494/500\n",
            "11/11 [==============================] - 0s 39ms/step - loss: 0.1480 - accuracy: 0.9444 - val_loss: 1.8288 - val_accuracy: 0.6181\n",
            "Epoch 495/500\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 0.1333 - accuracy: 0.9591 - val_loss: 1.8966 - val_accuracy: 0.6389\n",
            "Epoch 496/500\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.1289 - accuracy: 0.9576 - val_loss: 1.9362 - val_accuracy: 0.6528\n",
            "Epoch 497/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.1174 - accuracy: 0.9614 - val_loss: 1.7856 - val_accuracy: 0.6458\n",
            "Epoch 498/500\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.1200 - accuracy: 0.9637 - val_loss: 1.8413 - val_accuracy: 0.6389\n",
            "Epoch 499/500\n",
            "11/11 [==============================] - 0s 39ms/step - loss: 0.1042 - accuracy: 0.9668 - val_loss: 1.8866 - val_accuracy: 0.6597\n",
            "Epoch 500/500\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.1310 - accuracy: 0.9560 - val_loss: 1.8513 - val_accuracy: 0.6389\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_10 (Conv1D)           (None, 22, 192)           768       \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 22, 192)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_10 (MaxPooling (None, 11, 192)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_11 (Conv1D)           (None, 9, 64)             36928     \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 9, 64)             0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_11 (MaxPooling (None, 4, 64)             0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 9)                 585       \n",
            "=================================================================\n",
            "Total params: 54,729\n",
            "Trainable params: 54,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}